Poe => adk api_server
INFO:     Started server process [55598]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
INFO:     Uvicorn running on http://127.0.0.1:8000 (Press CTRL+C to quit)
INFO:     127.0.0.1:62675 - "GET /list-apps HTTP/1.1" 200 OK
2025-06-30 03:48:51,608 - INFO - fast_api.py:430 - New session created: test_session_001
INFO:     127.0.0.1:63193 - "POST /apps/reframe_agent/users/test_user_001/sessions/test_session_001 HTTP/1.1" 200 OK
2025-06-30 03:49:05,583 - INFO - envs.py:54 - No .env file found for reframe_agent
2025-06-30 03:49:05,583 - INFO - envs.py:54 - No .env file found for reframe_agent
2025-06-30 03:49:05,762 - INFO - agent_loader.py:95 - Found root_agent in reframe_agent.agent
2025-06-30 03:49:05,764 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:49:05,833 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:49:05,833 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I would like to start the session"}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:49:05,833 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:49:06,684 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I understand. I'm here to help you describe a challenging social situation. Let's start by talking about the specific situation. Can you describe the social situation that was challenging for you? Please provide as much detail as possible.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:49:06 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=762","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I understand. I'm here to help you describe a challenging social situation. Let's start by talking about the specific situation. Can you describe the social situation that was challenging for you? Please provide as much detail as possible.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.20603543519973755}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":48,"candidates_tokens_details":[{"modality":"TEXT","token_count":48}],"prompt_token_count":191,"prompt_tokens_details":[{"modality":"TEXT","token_count":191}],"total_token_count":239},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:49:06,690 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:49:06,751 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:49:06,751 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I would like to start the session"}],"role":"user"}
{"parts":[{"text":"I understand. I'm here to help you describe a challenging social situation. Let's start by talking about the specific situation. Can you describe the social situation that was challenging for you? Please provide as much detail as possible.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:49:06,751 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:49:07,532 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
Okay, I'm ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:49:07 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=701","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"Okay, I'm ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.46094986700242563}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":31,"candidates_tokens_details":[{"modality":"TEXT","token_count":31}],"prompt_token_count":258,"prompt_tokens_details":[{"modality":"TEXT","token_count":258}],"total_token_count":289},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:49:07,536 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:49:07,594 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:49:07,594 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I would like to start the session"}],"role":"user"}
{"parts":[{"text":"I understand. I'm here to help you describe a challenging social situation. Let's start by talking about the specific situation. Can you describe the social situation that was challenging for you? Please provide as much detail as possible.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:49:07,594 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:49:08,607 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am ready to continue. Can you please describe the challenging social situation you'd like to discuss? I want to understand the specific details of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:49:08 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=838","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am ready to continue. Can you please describe the challenging social situation you'd like to discuss? I want to understand the specific details of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.3628874692049893}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":33,"candidates_tokens_details":[{"modality":"TEXT","token_count":33}],"prompt_token_count":289,"prompt_tokens_details":[{"modality":"TEXT","token_count":289}],"total_token_count":322},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:49:08,613 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:49:08,676 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:49:08,676 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I would like to start the session"}],"role":"user"}
{"parts":[{"text":"I understand. I'm here to help you describe a challenging social situation. Let's start by talking about the specific situation. Can you describe the social situation that was challenging for you? Please provide as much detail as possible.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue. Can you please describe the challenging social situation you'd like to discuss? I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:49:08,676 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:49:09,403 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
Okay, I'm ready to continue. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:49:09 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=647","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"Okay, I'm ready to continue. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.0894236494513119}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":34,"candidates_tokens_details":[{"modality":"TEXT","token_count":34}],"prompt_token_count":322,"prompt_tokens_details":[{"modality":"TEXT","token_count":322}],"total_token_count":356},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:49:09,411 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:49:09,471 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:49:09,471 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I would like to start the session"}],"role":"user"}
{"parts":[{"text":"I understand. I'm here to help you describe a challenging social situation. Let's start by talking about the specific situation. Can you describe the social situation that was challenging for you? Please provide as much detail as possible.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue. Can you please describe the challenging social situation you'd like to discuss? I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready to continue. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:49:09,471 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:49:10,354 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:49:10 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=793","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.15505146980285645}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":28,"candidates_tokens_details":[{"modality":"TEXT","token_count":28}],"prompt_token_count":356,"prompt_tokens_details":[{"modality":"TEXT","token_count":356}],"total_token_count":384},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:49:10,358 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:49:10,409 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:49:10,409 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I would like to start the session"}],"role":"user"}
{"parts":[{"text":"I understand. I'm here to help you describe a challenging social situation. Let's start by talking about the specific situation. Can you describe the social situation that was challenging for you? Please provide as much detail as possible.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue. Can you please describe the challenging social situation you'd like to discuss? I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready to continue. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:49:10,409 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:49:11,070 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:49:11 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=582","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.11273411224628317}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":29,"candidates_tokens_details":[{"modality":"TEXT","token_count":29}],"prompt_token_count":384,"prompt_tokens_details":[{"modality":"TEXT","token_count":384}],"total_token_count":413},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:49:11,073 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:49:11,121 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:49:11,121 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I would like to start the session"}],"role":"user"}
{"parts":[{"text":"I understand. I'm here to help you describe a challenging social situation. Let's start by talking about the specific situation. Can you describe the social situation that was challenging for you? Please provide as much detail as possible.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue. Can you please describe the challenging social situation you'd like to discuss? I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready to continue. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:49:11,121 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:49:11,840 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:49:11 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=618","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.2398673912574505}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":29,"candidates_tokens_details":[{"modality":"TEXT","token_count":29}],"prompt_token_count":413,"prompt_tokens_details":[{"modality":"TEXT","token_count":413}],"total_token_count":442},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:49:11,846 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:49:11,906 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:49:11,906 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I would like to start the session"}],"role":"user"}
{"parts":[{"text":"I understand. I'm here to help you describe a challenging social situation. Let's start by talking about the specific situation. Can you describe the social situation that was challenging for you? Please provide as much detail as possible.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue. Can you please describe the challenging social situation you'd like to discuss? I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready to continue. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:49:11,906 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:49:12,603 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
Okay, I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:49:12 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=544","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"Okay, I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.13869136379611108}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":31,"candidates_tokens_details":[{"modality":"TEXT","token_count":31}],"prompt_token_count":442,"prompt_tokens_details":[{"modality":"TEXT","token_count":442}],"total_token_count":473},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:49:12,609 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:49:12,672 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:49:12,672 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I would like to start the session"}],"role":"user"}
{"parts":[{"text":"I understand. I'm here to help you describe a challenging social situation. Let's start by talking about the specific situation. Can you describe the social situation that was challenging for you? Please provide as much detail as possible.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue. Can you please describe the challenging social situation you'd like to discuss? I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready to continue. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:49:12,672 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:49:13,368 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:49:13 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=605","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.014912932083524507}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":29,"candidates_tokens_details":[{"modality":"TEXT","token_count":29}],"prompt_token_count":473,"prompt_tokens_details":[{"modality":"TEXT","token_count":473}],"total_token_count":502},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:49:13,374 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:49:13,436 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:49:13,436 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I would like to start the session"}],"role":"user"}
{"parts":[{"text":"I understand. I'm here to help you describe a challenging social situation. Let's start by talking about the specific situation. Can you describe the social situation that was challenging for you? Please provide as much detail as possible.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue. Can you please describe the challenging social situation you'd like to discuss? I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready to continue. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:49:13,436 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:49:14,155 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:49:14 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=638","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.010844623220377955}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":29,"candidates_tokens_details":[{"modality":"TEXT","token_count":29}],"prompt_token_count":502,"prompt_tokens_details":[{"modality":"TEXT","token_count":502}],"total_token_count":531},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:49:14,159 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:49:14,220 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:49:14,221 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I would like to start the session"}],"role":"user"}
{"parts":[{"text":"I understand. I'm here to help you describe a challenging social situation. Let's start by talking about the specific situation. Can you describe the social situation that was challenging for you? Please provide as much detail as possible.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue. Can you please describe the challenging social situation you'd like to discuss? I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready to continue. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:49:14,221 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:49:14,976 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:49:15 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=674","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.00974520938149814}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":29,"candidates_tokens_details":[{"modality":"TEXT","token_count":29}],"prompt_token_count":531,"prompt_tokens_details":[{"modality":"TEXT","token_count":531}],"total_token_count":560},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:49:14,983 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:49:15,043 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:49:15,043 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I would like to start the session"}],"role":"user"}
{"parts":[{"text":"I understand. I'm here to help you describe a challenging social situation. Let's start by talking about the specific situation. Can you describe the social situation that was challenging for you? Please provide as much detail as possible.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue. Can you please describe the challenging social situation you'd like to discuss? I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready to continue. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. Tell me about the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:49:15,043 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:49:15,811 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:49:15 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=673","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am ready. Please describe the challenging social situation you'd like to discuss. I want to understand the specific details of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.010140485804656455}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":29,"candidates_tokens_details":[{"modality":"TEXT","token_count":29}],"prompt_token_count":560,"prompt_tokens_details":[{"modality":"TEXT","token_count":560}],"total_token_count":589},"automatic_function_calling_history":[]}
-----------------------------------------------------------

INFO:     127.0.0.1:63267 - "POST /run HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/uvicorn/protocols/http/h11_impl.py", line 403, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/routing.py", line 714, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/routing.py", line 734, in app
    await route.handle(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/cli/fast_api.py", line 784, in agent_run
    events = [
             ^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/runners.py", line 203, in run_async
    async for event in invocation_context.agent.run_async(invocation_context):
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 147, in run_async
    async for event in self._run_async_impl(ctx):
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/agents/sequential_agent.py", line 37, in _run_async_impl
    async for event in sub_agent.run_async(ctx):
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 147, in run_async
    async for event in self._run_async_impl(ctx):
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 188, in _run_async_impl
    raise NotImplementedError(
NotImplementedError: _run_async_impl for <class 'app.agents.parser.JsonParserAgent'> is not implemented.
INFO:     127.0.0.1:64229 - "GET /list-apps HTTP/1.1" 200 OK
2025-06-30 03:51:35,850 - INFO - fast_api.py:430 - New session created: test_session_1751248295
INFO:     127.0.0.1:64229 - "POST /apps/reframe_agent/users/test_user_1751248295/sessions/test_session_1751248295 HTTP/1.1" 200 OK
2025-06-30 03:51:35,852 - INFO - envs.py:54 - No .env file found for reframe_agent
2025-06-30 03:51:35,854 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:51:35,898 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:51:35,899 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:51:35,900 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:51:36,834 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I understand. I'm ready to listen and help you describe a challenging social situation. To begin, could you tell me about the specific social situation you'd like to discuss? What happened, and where were you?

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:51:36 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=832","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I understand. I'm ready to listen and help you describe a challenging social situation. To begin, could you tell me about the specific social situation you'd like to discuss? What happened, and where were you?\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.2668594277423361}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":46,"candidates_tokens_details":[{"modality":"TEXT","token_count":46}],"prompt_token_count":194,"prompt_tokens_details":[{"modality":"TEXT","token_count":194}],"total_token_count":240},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:51:36,839 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:51:36,895 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:51:36,895 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"I understand. I'm ready to listen and help you describe a challenging social situation. To begin, could you tell me about the specific social situation you'd like to discuss? What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:51:36,895 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:51:37,684 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
Okay, I'm ready. Please, tell me about the challenging social situation you'd like to discuss. What happened, and where were you?

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:51:37 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=703","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"Okay, I'm ready. Please, tell me about the challenging social situation you'd like to discuss. What happened, and where were you?\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.3394638001918793}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":32,"candidates_tokens_details":[{"modality":"TEXT","token_count":32}],"prompt_token_count":259,"prompt_tokens_details":[{"modality":"TEXT","token_count":259}],"total_token_count":291},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:51:37,692 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:51:37,836 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:51:37,836 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"I understand. I'm ready to listen and help you describe a challenging social situation. To begin, could you tell me about the specific social situation you'd like to discuss? What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please, tell me about the challenging social situation you'd like to discuss. What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:51:37,836 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:51:38,582 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
Alright, let's dive in. Can you describe the challenging social situation you experienced? Please share as much detail as you're comfortable with, including where you were and what happened.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:51:38 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=664","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"Alright, let's dive in. Can you describe the challenging social situation you experienced? Please share as much detail as you're comfortable with, including where you were and what happened.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.5555023780235877}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":39,"candidates_tokens_details":[{"modality":"TEXT","token_count":39}],"prompt_token_count":291,"prompt_tokens_details":[{"modality":"TEXT","token_count":291}],"total_token_count":330},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:51:38,584 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:51:38,625 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:51:38,625 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"I understand. I'm ready to listen and help you describe a challenging social situation. To begin, could you tell me about the specific social situation you'd like to discuss? What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please, tell me about the challenging social situation you'd like to discuss. What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Alright, let's dive in. Can you describe the challenging social situation you experienced? Please share as much detail as you're comfortable with, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:51:38,625 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:51:39,312 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
Okay, I will continue processing the previous requests as instructed. I am ready for you to describe the challenging social situation. Please provide details about the situation, including where you were and what happened.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:51:39 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=598","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"Okay, I will continue processing the previous requests as instructed. I am ready for you to describe the challenging social situation. Please provide details about the situation, including where you were and what happened.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.39617152214050294}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":40,"candidates_tokens_details":[{"modality":"TEXT","token_count":40}],"prompt_token_count":330,"prompt_tokens_details":[{"modality":"TEXT","token_count":330}],"total_token_count":370},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:51:39,319 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:51:39,381 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:51:39,381 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"I understand. I'm ready to listen and help you describe a challenging social situation. To begin, could you tell me about the specific social situation you'd like to discuss? What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please, tell me about the challenging social situation you'd like to discuss. What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Alright, let's dive in. Can you describe the challenging social situation you experienced? Please share as much detail as you're comfortable with, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I will continue processing the previous requests as instructed. I am ready for you to describe the challenging social situation. Please provide details about the situation, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:51:39,381 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:51:40,068 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am ready to continue the intake process. Please describe the challenging social situation you'd like to discuss.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:51:40 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=606","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am ready to continue the intake process. Please describe the challenging social situation you'd like to discuss.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.41894307343856146}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":23,"candidates_tokens_details":[{"modality":"TEXT","token_count":23}],"prompt_token_count":370,"prompt_tokens_details":[{"modality":"TEXT","token_count":370}],"total_token_count":393},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:51:40,071 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:51:40,120 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:51:40,120 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"I understand. I'm ready to listen and help you describe a challenging social situation. To begin, could you tell me about the specific social situation you'd like to discuss? What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please, tell me about the challenging social situation you'd like to discuss. What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Alright, let's dive in. Can you describe the challenging social situation you experienced? Please share as much detail as you're comfortable with, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I will continue processing the previous requests as instructed. I am ready for you to describe the challenging social situation. Please provide details about the situation, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue the intake process. Please describe the challenging social situation you'd like to discuss.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:51:40,120 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:51:40,872 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
Understood. Since I haven't received any new information, I will proceed with the instructions. Please provide the details about the challenging social situation, including the location and what happened. I'm ready when you are.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:51:40 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=670","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"Understood. Since I haven't received any new information, I will proceed with the instructions. Please provide the details about the challenging social situation, including the location and what happened. I'm ready when you are.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.47592569986979166}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":45,"candidates_tokens_details":[{"modality":"TEXT","token_count":45}],"prompt_token_count":393,"prompt_tokens_details":[{"modality":"TEXT","token_count":393}],"total_token_count":438},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:51:40,879 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:51:40,926 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:51:40,926 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"I understand. I'm ready to listen and help you describe a challenging social situation. To begin, could you tell me about the specific social situation you'd like to discuss? What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please, tell me about the challenging social situation you'd like to discuss. What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Alright, let's dive in. Can you describe the challenging social situation you experienced? Please share as much detail as you're comfortable with, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I will continue processing the previous requests as instructed. I am ready for you to describe the challenging social situation. Please provide details about the situation, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue the intake process. Please describe the challenging social situation you'd like to discuss.\n"}],"role":"model"}
{"parts":[{"text":"Understood. Since I haven't received any new information, I will proceed with the instructions. Please provide the details about the challenging social situation, including the location and what happened. I'm ready when you are.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:51:40,926 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:51:41,892 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am designed to collect information about a challenging social situation, including the situation itself, your thoughts and feelings, your behaviors, and the outcome. I need you to describe the situation to continue. Once I have gathered enough information, I will use the exit_loop tool. Please, describe the challenging social situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:51:41 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=878","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am designed to collect information about a challenging social situation, including the situation itself, your thoughts and feelings, your behaviors, and the outcome. I need you to describe the situation to continue. Once I have gathered enough information, I will use the exit_loop tool. Please, describe the challenging social situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.30607980489730835}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":64,"candidates_tokens_details":[{"modality":"TEXT","token_count":64}],"prompt_token_count":438,"prompt_tokens_details":[{"modality":"TEXT","token_count":438}],"total_token_count":502},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:51:41,910 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:51:42,047 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:51:42,047 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"I understand. I'm ready to listen and help you describe a challenging social situation. To begin, could you tell me about the specific social situation you'd like to discuss? What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please, tell me about the challenging social situation you'd like to discuss. What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Alright, let's dive in. Can you describe the challenging social situation you experienced? Please share as much detail as you're comfortable with, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I will continue processing the previous requests as instructed. I am ready for you to describe the challenging social situation. Please provide details about the situation, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue the intake process. Please describe the challenging social situation you'd like to discuss.\n"}],"role":"model"}
{"parts":[{"text":"Understood. Since I haven't received any new information, I will proceed with the instructions. Please provide the details about the challenging social situation, including the location and what happened. I'm ready when you are.\n"}],"role":"model"}
{"parts":[{"text":"I am designed to collect information about a challenging social situation, including the situation itself, your thoughts and feelings, your behaviors, and the outcome. I need you to describe the situation to continue. Once I have gathered enough information, I will use the exit_loop tool. Please, describe the challenging social situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:51:42,048 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:51:42,956 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I understand. However, I need more information to continue the intake process. I am designed to help you describe a challenging social situation. I need you to tell me about the specific social situation, your thoughts and feelings, your behaviors, and the outcome. Please provide the details of the situation so I can proceed.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:51:43 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=812","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I understand. However, I need more information to continue the intake process. I am designed to help you describe a challenging social situation. I need you to tell me about the specific social situation, your thoughts and feelings, your behaviors, and the outcome. Please provide the details of the situation so I can proceed.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.40166452527046204}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":64,"candidates_tokens_details":[{"modality":"TEXT","token_count":64}],"prompt_token_count":502,"prompt_tokens_details":[{"modality":"TEXT","token_count":502}],"total_token_count":566},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:51:42,976 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:51:43,042 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:51:43,042 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"I understand. I'm ready to listen and help you describe a challenging social situation. To begin, could you tell me about the specific social situation you'd like to discuss? What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please, tell me about the challenging social situation you'd like to discuss. What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Alright, let's dive in. Can you describe the challenging social situation you experienced? Please share as much detail as you're comfortable with, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I will continue processing the previous requests as instructed. I am ready for you to describe the challenging social situation. Please provide details about the situation, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue the intake process. Please describe the challenging social situation you'd like to discuss.\n"}],"role":"model"}
{"parts":[{"text":"Understood. Since I haven't received any new information, I will proceed with the instructions. Please provide the details about the challenging social situation, including the location and what happened. I'm ready when you are.\n"}],"role":"model"}
{"parts":[{"text":"I am designed to collect information about a challenging social situation, including the situation itself, your thoughts and feelings, your behaviors, and the outcome. I need you to describe the situation to continue. Once I have gathered enough information, I will use the exit_loop tool. Please, describe the challenging social situation.\n"}],"role":"model"}
{"parts":[{"text":"I understand. However, I need more information to continue the intake process. I am designed to help you describe a challenging social situation. I need you to tell me about the specific social situation, your thoughts and feelings, your behaviors, and the outcome. Please provide the details of the situation so I can proceed.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:51:43,042 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:51:43,795 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am designed to gather information about a challenging social situation, including the specific situation, your thoughts and feelings, your behaviors, and the outcome. I need you to describe the situation to proceed. Once I have gathered sufficient details, I will use the exit_loop tool. Please, describe the challenging social situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:51:43 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=672","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am designed to gather information about a challenging social situation, including the specific situation, your thoughts and feelings, your behaviors, and the outcome. I need you to describe the situation to proceed. Once I have gathered sufficient details, I will use the exit_loop tool. Please, describe the challenging social situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.24890919029712677}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":64,"candidates_tokens_details":[{"modality":"TEXT","token_count":64}],"prompt_token_count":566,"prompt_tokens_details":[{"modality":"TEXT","token_count":566}],"total_token_count":630},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:51:43,797 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:51:43,844 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:51:43,844 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"I understand. I'm ready to listen and help you describe a challenging social situation. To begin, could you tell me about the specific social situation you'd like to discuss? What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please, tell me about the challenging social situation you'd like to discuss. What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Alright, let's dive in. Can you describe the challenging social situation you experienced? Please share as much detail as you're comfortable with, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I will continue processing the previous requests as instructed. I am ready for you to describe the challenging social situation. Please provide details about the situation, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue the intake process. Please describe the challenging social situation you'd like to discuss.\n"}],"role":"model"}
{"parts":[{"text":"Understood. Since I haven't received any new information, I will proceed with the instructions. Please provide the details about the challenging social situation, including the location and what happened. I'm ready when you are.\n"}],"role":"model"}
{"parts":[{"text":"I am designed to collect information about a challenging social situation, including the situation itself, your thoughts and feelings, your behaviors, and the outcome. I need you to describe the situation to continue. Once I have gathered enough information, I will use the exit_loop tool. Please, describe the challenging social situation.\n"}],"role":"model"}
{"parts":[{"text":"I understand. However, I need more information to continue the intake process. I am designed to help you describe a challenging social situation. I need you to tell me about the specific social situation, your thoughts and feelings, your behaviors, and the outcome. Please provide the details of the situation so I can proceed.\n"}],"role":"model"}
{"parts":[{"text":"I am designed to gather information about a challenging social situation, including the specific situation, your thoughts and feelings, your behaviors, and the outcome. I need you to describe the situation to proceed. Once I have gathered sufficient details, I will use the exit_loop tool. Please, describe the challenging social situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:51:43,844 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:51:44,684 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am designed to gather detailed information about a challenging social situation. Since I haven't received any information about a specific situation, I am unable to proceed. I need you to describe the challenging social situation, including the specifics of what happened, your thoughts and feelings, your behaviors, and the outcome.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:51:44 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=759","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am designed to gather detailed information about a challenging social situation. Since I haven't received any information about a specific situation, I am unable to proceed. I need you to describe the challenging social situation, including the specifics of what happened, your thoughts and feelings, your behaviors, and the outcome.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.27688709382087956}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":62,"candidates_tokens_details":[{"modality":"TEXT","token_count":62}],"prompt_token_count":630,"prompt_tokens_details":[{"modality":"TEXT","token_count":630}],"total_token_count":692},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:51:44,691 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:51:44,756 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:51:44,756 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"I understand. I'm ready to listen and help you describe a challenging social situation. To begin, could you tell me about the specific social situation you'd like to discuss? What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please, tell me about the challenging social situation you'd like to discuss. What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Alright, let's dive in. Can you describe the challenging social situation you experienced? Please share as much detail as you're comfortable with, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I will continue processing the previous requests as instructed. I am ready for you to describe the challenging social situation. Please provide details about the situation, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue the intake process. Please describe the challenging social situation you'd like to discuss.\n"}],"role":"model"}
{"parts":[{"text":"Understood. Since I haven't received any new information, I will proceed with the instructions. Please provide the details about the challenging social situation, including the location and what happened. I'm ready when you are.\n"}],"role":"model"}
{"parts":[{"text":"I am designed to collect information about a challenging social situation, including the situation itself, your thoughts and feelings, your behaviors, and the outcome. I need you to describe the situation to continue. Once I have gathered enough information, I will use the exit_loop tool. Please, describe the challenging social situation.\n"}],"role":"model"}
{"parts":[{"text":"I understand. However, I need more information to continue the intake process. I am designed to help you describe a challenging social situation. I need you to tell me about the specific social situation, your thoughts and feelings, your behaviors, and the outcome. Please provide the details of the situation so I can proceed.\n"}],"role":"model"}
{"parts":[{"text":"I am designed to gather information about a challenging social situation, including the specific situation, your thoughts and feelings, your behaviors, and the outcome. I need you to describe the situation to proceed. Once I have gathered sufficient details, I will use the exit_loop tool. Please, describe the challenging social situation.\n"}],"role":"model"}
{"parts":[{"text":"I am designed to gather detailed information about a challenging social situation. Since I haven't received any information about a specific situation, I am unable to proceed. I need you to describe the challenging social situation, including the specifics of what happened, your thoughts and feelings, your behaviors, and the outcome.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:51:44,756 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:51:45,698 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am designed to help you describe a challenging social situation. To proceed, I need you to describe the specific social situation. Please provide details about what happened, where you were, and who was involved. I need this information to understand the situation and gather details about your thoughts, feelings, behaviors, and the outcome.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:51:45 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=820","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am designed to help you describe a challenging social situation. To proceed, I need you to describe the specific social situation. Please provide details about what happened, where you were, and who was involved. I need this information to understand the situation and gather details about your thoughts, feelings, behaviors, and the outcome.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.26710516122671274}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":65,"candidates_tokens_details":[{"modality":"TEXT","token_count":65}],"prompt_token_count":692,"prompt_tokens_details":[{"modality":"TEXT","token_count":692}],"total_token_count":757},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:51:45,707 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:51:45,766 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:51:45,766 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"I understand. I'm ready to listen and help you describe a challenging social situation. To begin, could you tell me about the specific social situation you'd like to discuss? What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please, tell me about the challenging social situation you'd like to discuss. What happened, and where were you?\n"}],"role":"model"}
{"parts":[{"text":"Alright, let's dive in. Can you describe the challenging social situation you experienced? Please share as much detail as you're comfortable with, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I will continue processing the previous requests as instructed. I am ready for you to describe the challenging social situation. Please provide details about the situation, including where you were and what happened.\n"}],"role":"model"}
{"parts":[{"text":"I am ready to continue the intake process. Please describe the challenging social situation you'd like to discuss.\n"}],"role":"model"}
{"parts":[{"text":"Understood. Since I haven't received any new information, I will proceed with the instructions. Please provide the details about the challenging social situation, including the location and what happened. I'm ready when you are.\n"}],"role":"model"}
{"parts":[{"text":"I am designed to collect information about a challenging social situation, including the situation itself, your thoughts and feelings, your behaviors, and the outcome. I need you to describe the situation to continue. Once I have gathered enough information, I will use the exit_loop tool. Please, describe the challenging social situation.\n"}],"role":"model"}
{"parts":[{"text":"I understand. However, I need more information to continue the intake process. I am designed to help you describe a challenging social situation. I need you to tell me about the specific social situation, your thoughts and feelings, your behaviors, and the outcome. Please provide the details of the situation so I can proceed.\n"}],"role":"model"}
{"parts":[{"text":"I am designed to gather information about a challenging social situation, including the specific situation, your thoughts and feelings, your behaviors, and the outcome. I need you to describe the situation to proceed. Once I have gathered sufficient details, I will use the exit_loop tool. Please, describe the challenging social situation.\n"}],"role":"model"}
{"parts":[{"text":"I am designed to gather detailed information about a challenging social situation. Since I haven't received any information about a specific situation, I am unable to proceed. I need you to describe the challenging social situation, including the specifics of what happened, your thoughts and feelings, your behaviors, and the outcome.\n"}],"role":"model"}
{"parts":[{"text":"I am designed to help you describe a challenging social situation. To proceed, I need you to describe the specific social situation. Please provide details about what happened, where you were, and who was involved. I need this information to understand the situation and gather details about your thoughts, feelings, behaviors, and the outcome.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:51:45,766 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:51:46,691 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I understand. However, I haven't received any information about a challenging social situation to process. I am designed to help you describe such a situation. To proceed, I need you to describe a specific situation, including what happened, where you were, and who was involved. Please provide the details so I can gather information about your thoughts, feelings, behaviors, and the outcome.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:51:46 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=834","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I understand. However, I haven't received any information about a challenging social situation to process. I am designed to help you describe such a situation. To proceed, I need you to describe a specific situation, including what happened, where you were, and who was involved. Please provide the details so I can gather information about your thoughts, feelings, behaviors, and the outcome.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.3414615239852514}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":78,"candidates_tokens_details":[{"modality":"TEXT","token_count":78}],"prompt_token_count":757,"prompt_tokens_details":[{"modality":"TEXT","token_count":757}],"total_token_count":835},"automatic_function_calling_history":[]}
-----------------------------------------------------------

INFO:     127.0.0.1:64229 - "POST /run HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/uvicorn/protocols/http/h11_impl.py", line 403, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/routing.py", line 714, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/routing.py", line 734, in app
    await route.handle(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/cli/fast_api.py", line 784, in agent_run
    events = [
             ^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/runners.py", line 203, in run_async
    async for event in invocation_context.agent.run_async(invocation_context):
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 147, in run_async
    async for event in self._run_async_impl(ctx):
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/agents/sequential_agent.py", line 37, in _run_async_impl
    async for event in sub_agent.run_async(ctx):
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 147, in run_async
    async for event in self._run_async_impl(ctx):
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 188, in _run_async_impl
    raise NotImplementedError(
NotImplementedError: _run_async_impl for <class 'app.agents.parser.JsonParserAgent'> is not implemented.
INFO:     127.0.0.1:64298 - "GET /debug/trace/session/test_session_1751248295 HTTP/1.1" 200 OK
INFO:     127.0.0.1:64298 - "GET /apps/reframe_agent/users/test_user_1751248295/sessions/test_session_1751248295 HTTP/1.1" 200 OK
INFO:     127.0.0.1:64298 - "DELETE /apps/reframe_agent/users/test_user_1751248295/sessions/test_session_1751248295 HTTP/1.1" 200 OK
INFO:     127.0.0.1:64551 - "GET /list-apps HTTP/1.1" 200 OK
2025-06-30 03:52:30,932 - INFO - fast_api.py:430 - New session created: test_session_1751248350
INFO:     127.0.0.1:64551 - "POST /apps/reframe_agent/users/test_user_1751248350/sessions/test_session_1751248350 HTTP/1.1" 200 OK
2025-06-30 03:52:30,934 - INFO - envs.py:54 - No .env file found for reframe_agent
2025-06-30 03:52:30,939 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:52:31,023 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:52:31,024 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:52:31,024 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:52:31,904 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:52:31 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=784","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.3312059833157447}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":31,"candidates_tokens_details":[{"modality":"TEXT","token_count":31}],"prompt_token_count":194,"prompt_tokens_details":[{"modality":"TEXT","token_count":194}],"total_token_count":225},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:52:31,909 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:52:31,969 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:52:31,969 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:52:31,969 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:52:32,676 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:52:32 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=598","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.08909842275804089}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":31,"candidates_tokens_details":[{"modality":"TEXT","token_count":31}],"prompt_token_count":244,"prompt_tokens_details":[{"modality":"TEXT","token_count":244}],"total_token_count":275},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:52:32,682 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:52:32,737 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:52:32,737 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:52:32,737 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:52:33,324 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:52:33 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=507","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.2333259274882655}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":31,"candidates_tokens_details":[{"modality":"TEXT","token_count":31}],"prompt_token_count":275,"prompt_tokens_details":[{"modality":"TEXT","token_count":275}],"total_token_count":306},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:52:33,332 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:52:33,393 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:52:33,393 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:52:33,393 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:52:34,307 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
Okay, I understand. Let's start with the challenging social situation. Please describe it in as much detail as possible. What happened? Where were you? Who was involved? What was the context?

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:52:34 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=833","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"Okay, I understand. Let's start with the challenging social situation. Please describe it in as much detail as possible. What happened? Where were you? Who was involved? What was the context?\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.26125894274030415}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":42,"candidates_tokens_details":[{"modality":"TEXT","token_count":42}],"prompt_token_count":306,"prompt_tokens_details":[{"modality":"TEXT","token_count":306}],"total_token_count":348},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:52:34,313 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:52:34,377 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:52:34,377 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I understand. Let's start with the challenging social situation. Please describe it in as much detail as possible. What happened? Where were you? Who was involved? What was the context?\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:52:34,378 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:52:35,231 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:52:35 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=764","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.22441851009022107}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":44,"candidates_tokens_details":[{"modality":"TEXT","token_count":44}],"prompt_token_count":348,"prompt_tokens_details":[{"modality":"TEXT","token_count":348}],"total_token_count":392},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:52:35,233 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:52:35,274 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:52:35,274 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I understand. Let's start with the challenging social situation. Please describe it in as much detail as possible. What happened? Where were you? Who was involved? What was the context?\n"}],"role":"model"}
{"parts":[{"text":"I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:52:35,274 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:52:36,010 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:52:36 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=657","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.04273319786245173}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":44,"candidates_tokens_details":[{"modality":"TEXT","token_count":44}],"prompt_token_count":392,"prompt_tokens_details":[{"modality":"TEXT","token_count":392}],"total_token_count":436},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:52:36,015 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:52:36,070 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:52:36,071 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I understand. Let's start with the challenging social situation. Please describe it in as much detail as possible. What happened? Where were you? Who was involved? What was the context?\n"}],"role":"model"}
{"parts":[{"text":"I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:52:36,071 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:52:36,832 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:52:36 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=684","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.0388935536146164}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":40,"candidates_tokens_details":[{"modality":"TEXT","token_count":40}],"prompt_token_count":436,"prompt_tokens_details":[{"modality":"TEXT","token_count":436}],"total_token_count":476},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:52:36,838 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:52:36,901 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:52:36,901 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I understand. Let's start with the challenging social situation. Please describe it in as much detail as possible. What happened? Where were you? Who was involved? What was the context?\n"}],"role":"model"}
{"parts":[{"text":"I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:52:36,901 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:52:37,549 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am ready. Please describe the challenging social situation. Tell me what happened, where you were, who was involved, and the context.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:52:37 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=567","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am ready. Please describe the challenging social situation. Tell me what happened, where you were, who was involved, and the context.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.23997315045060783}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":29,"candidates_tokens_details":[{"modality":"TEXT","token_count":29}],"prompt_token_count":476,"prompt_tokens_details":[{"modality":"TEXT","token_count":476}],"total_token_count":505},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:52:37,556 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:52:37,620 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:52:37,620 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I understand. Let's start with the challenging social situation. Please describe it in as much detail as possible. What happened? Where were you? Who was involved? What was the context?\n"}],"role":"model"}
{"parts":[{"text":"I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation. Tell me what happened, where you were, who was involved, and the context.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:52:37,620 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:52:38,439 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:52:38 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=723","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.06230358481407165}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":40,"candidates_tokens_details":[{"modality":"TEXT","token_count":40}],"prompt_token_count":505,"prompt_tokens_details":[{"modality":"TEXT","token_count":505}],"total_token_count":545},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:52:38,445 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:52:38,502 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:52:38,502 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I understand. Let's start with the challenging social situation. Please describe it in as much detail as possible. What happened? Where were you? Who was involved? What was the context?\n"}],"role":"model"}
{"parts":[{"text":"I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation. Tell me what happened, where you were, who was involved, and the context.\n"}],"role":"model"}
{"parts":[{"text":"I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:52:38,502 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:52:39,195 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am ready. Please describe the challenging social situation. Tell me what happened, where you were, who was involved, and the context.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:52:39 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=615","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am ready. Please describe the challenging social situation. Tell me what happened, where you were, who was involved, and the context.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.0470565886333071}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":29,"candidates_tokens_details":[{"modality":"TEXT","token_count":29}],"prompt_token_count":545,"prompt_tokens_details":[{"modality":"TEXT","token_count":545}],"total_token_count":574},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:52:39,201 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:52:39,265 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:52:39,265 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I understand. Let's start with the challenging social situation. Please describe it in as much detail as possible. What happened? Where were you? Who was involved? What was the context?\n"}],"role":"model"}
{"parts":[{"text":"I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation. Tell me what happened, where you were, who was involved, and the context.\n"}],"role":"model"}
{"parts":[{"text":"I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation. Tell me what happened, where you were, who was involved, and the context.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:52:39,265 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:52:40,083 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:52:40 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=740","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.03819440603256226}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":40,"candidates_tokens_details":[{"modality":"TEXT","token_count":40}],"prompt_token_count":574,"prompt_tokens_details":[{"modality":"TEXT","token_count":574}],"total_token_count":614},"automatic_function_calling_history":[]}
-----------------------------------------------------------

2025-06-30 03:52:40,090 - WARNING - _api_client.py:107 - Both GOOGLE_API_KEY and GEMINI_API_KEY are set. Using GOOGLE_API_KEY.
2025-06-30 03:52:40,151 - INFO - google_llm.py:90 - Sending out request, model: gemini-2.0-flash-lite, backend: GoogleLLMVariant.GEMINI_API, stream: False
2025-06-30 03:52:40,152 - INFO - google_llm.py:96 - 
LLM Request:
-----------------------------------------------------------
System Instruction:
You are a compassionate intake specialist helping users describe their challenging social situations.

Your goal is to gather detailed information about:
1. The specific social situation that was challenging
2. Their thoughts and feelings during the situation
3. How they responded or what behaviors they engaged in
4. The outcome and how they felt afterward

Guidelines:
- Be empathetic and non-judgmental
- Ask clarifying questions to get specific details
- Help them identify thoughts, feelings, and behaviors
- Once you have a complete picture, use the exit_loop tool to proceed

IMPORTANT: Call exit_loop ONLY when you have gathered sufficient details about the situation, thoughts, feelings, behaviors, and outcomes.

You are an agent. Your internal name is "CollectorLLM".
-----------------------------------------------------------
Contents:
{"parts":[{"text":"Hello, I'd like to start the intake process."}],"role":"user"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I'm ready. Please tell me about the social situation you found challenging. The more detail you provide, the better I can understand.\n"}],"role":"model"}
{"parts":[{"text":"Okay, I understand. Let's start with the challenging social situation. Please describe it in as much detail as possible. What happened? Where were you? Who was involved? What was the context?\n"}],"role":"model"}
{"parts":[{"text":"I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am sorry, I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation. Tell me what happened, where you were, who was involved, and the context.\n"}],"role":"model"}
{"parts":[{"text":"I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"I am ready. Please describe the challenging social situation. Tell me what happened, where you were, who was involved, and the context.\n"}],"role":"model"}
{"parts":[{"text":"I am still waiting for you to describe the challenging social situation. Please provide as much detail as possible about what happened, where you were, who was involved, and the context of the situation.\n"}],"role":"model"}
{"parts":[{"text":"Continue processing previous requests as instructed. Exit or provide a summary if no more outputs are needed."}],"role":"user"}
-----------------------------------------------------------
Functions:
_exit_loop: {} 
-----------------------------------------------------------

2025-06-30 03:52:40,152 - INFO - models.py:7415 - AFC is enabled with max remote calls: 10.
2025-06-30 03:52:40,904 - INFO - google_llm.py:175 - 
LLM Response:
-----------------------------------------------------------
Text:
I apologize for the repetition. I am ready. Please describe the challenging social situation. Tell me what happened, where you were, who was involved, and the context.

-----------------------------------------------------------
Function calls:

-----------------------------------------------------------
Raw response:
{"sdk_http_response":{"headers":{"Content-Type":"application/json; charset=UTF-8","Vary":"Referer","Content-Encoding":"gzip","Date":"Mon, 30 Jun 2025 01:52:40 GMT","Server":"scaffolding on HTTPServer2","X-XSS-Protection":"0","X-Frame-Options":"SAMEORIGIN","X-Content-Type-Options":"nosniff","Server-Timing":"gfet4t7; dur=671","Alt-Svc":"h3=\":443\"; ma=2592000,h3-29=\":443\"; ma=2592000","Transfer-Encoding":"chunked"}},"candidates":[{"content":{"parts":[{"text":"I apologize for the repetition. I am ready. Please describe the challenging social situation. Tell me what happened, where you were, who was involved, and the context.\n"}],"role":"model"},"finish_reason":"STOP","avg_logprobs":-0.17808403287615096}],"model_version":"gemini-2.0-flash-lite","usage_metadata":{"candidates_token_count":35,"candidates_tokens_details":[{"modality":"TEXT","token_count":35}],"prompt_token_count":614,"prompt_tokens_details":[{"modality":"TEXT","token_count":614}],"total_token_count":649},"automatic_function_calling_history":[]}
-----------------------------------------------------------

INFO:     127.0.0.1:64551 - "POST /run HTTP/1.1" 500 Internal Server Error
ERROR:    Exception in ASGI application
Traceback (most recent call last):
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/uvicorn/protocols/http/h11_impl.py", line 403, in run_asgi
    result = await app(  # type: ignore[func-returns-value]
             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/uvicorn/middleware/proxy_headers.py", line 60, in __call__
    return await self.app(scope, receive, send)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/fastapi/applications.py", line 1054, in __call__
    await super().__call__(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/applications.py", line 112, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 187, in __call__
    raise exc
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/middleware/errors.py", line 165, in __call__
    await self.app(scope, receive, _send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/middleware/exceptions.py", line 62, in __call__
    await wrap_app_handling_exceptions(self.app, conn)(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/routing.py", line 714, in __call__
    await self.middleware_stack(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/routing.py", line 734, in app
    await route.handle(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/routing.py", line 288, in handle
    await self.app(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/routing.py", line 76, in app
    await wrap_app_handling_exceptions(app, request)(scope, receive, send)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 53, in wrapped_app
    raise exc
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/_exception_handler.py", line 42, in wrapped_app
    await app(scope, receive, sender)
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/starlette/routing.py", line 73, in app
    response = await f(request)
               ^^^^^^^^^^^^^^^^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/fastapi/routing.py", line 301, in app
    raw_response = await run_endpoint_function(
                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/fastapi/routing.py", line 212, in run_endpoint_function
    return await dependant.call(**values)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/cli/fast_api.py", line 784, in agent_run
    events = [
             ^
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/runners.py", line 203, in run_async
    async for event in invocation_context.agent.run_async(invocation_context):
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 147, in run_async
    async for event in self._run_async_impl(ctx):
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/agents/sequential_agent.py", line 37, in _run_async_impl
    async for event in sub_agent.run_async(ctx):
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 147, in run_async
    async for event in self._run_async_impl(ctx):
  File "/Users/carlos/workspace/reframe_agents_cloudandcarlos/.venv/lib/python3.12/site-packages/google/adk/agents/base_agent.py", line 188, in _run_async_impl
    raise NotImplementedError(
NotImplementedError: _run_async_impl for <class 'app.agents.parser.JsonParserAgent'> is not implemented.
INFO:     127.0.0.1:64605 - "GET /apps/reframe_agent/users/test_user_1751248350/sessions/test_session_1751248350 HTTP/1.1" 200 OK
INFO:     127.0.0.1:64605 - "DELETE /apps/reframe_agent/users/test_user_1751248350/sessions/test_session_1751248350 HTTP/1.1" 200 OK
